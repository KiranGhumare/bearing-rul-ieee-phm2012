{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b416bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating Remaining Useful Life of Ball Bearings\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimating Remaining Useful Life of Ball Bearings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5bfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d6e7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_value(df):\n",
    "    mean_abs_hor= np.sum(abs(df.iloc[:, -3]))\n",
    "    mean_abs_ver= np.sum(abs(df.iloc[:, -2]))\n",
    "    mean_abs_hor = mean_abs_hor/df.shape[0]\n",
    "    mean_abs_ver = mean_abs_ver/df.shape[0]\n",
    "    return mean_abs_hor, mean_abs_ver\n",
    "\n",
    "def peak_value(df):\n",
    "    peak_hor = max(abs(df.iloc[:, -3]))\n",
    "    peak_ver = max(abs(df.iloc[:, -2]))\n",
    "    return peak_hor, peak_ver\n",
    "\n",
    "def min_value(df):\n",
    "    min_hor = min(abs(df.iloc[:, -3]))\n",
    "    min_ver = min(abs(df.iloc[:, -2]))\n",
    "    return min_hor, min_ver\n",
    "\n",
    "def mean_value(df):\n",
    "    mean_hor = np.sum(df.iloc[:, -3])\n",
    "    mean_ver = np.sum(df.iloc[:, -2])\n",
    "    mean_hor = mean_hor/df.shape[0]\n",
    "    mean_ver = mean_ver/df.shape[0]\n",
    "    return mean_hor, mean_ver\n",
    "\n",
    "def max_value(df):\n",
    "    max_hor = max(abs(df.iloc[:, -3]))\n",
    "    max_ver = max(abs(df.iloc[:, -2]))\n",
    "    return max_hor, max_ver\n",
    "\n",
    "def rms_value(df):\n",
    "    rms_hor= np.sum(df.iloc[:, -3]**2)\n",
    "    rms_ver= np.sum(df.iloc[:, -2]**2)\n",
    "    rms_hor = np.sqrt(rms_hor/df.shape[0])\n",
    "    rms_ver = np.sqrt(rms_ver/df.shape[0])\n",
    "    return rms_hor, rms_ver\n",
    "\n",
    "def root_amplitude_value(df):\n",
    "    root_amplitude_hor = np.sum(np.sqrt(abs(df.iloc[:, -3]**2)))\n",
    "    root_amplitude_ver = np.sum(np.sqrt(abs(df.iloc[:, -2]**2)))\n",
    "    root_amplitude_hor = (root_amplitude_hor/df.shape[0])**2\n",
    "    root_amplitude_ver = (root_amplitude_ver/df.shape[0])**2\n",
    "    return root_amplitude_hor, root_amplitude_ver\n",
    "\n",
    "def variance_value(df):\n",
    "    variance_hor = np.sum((df.iloc[:, -3]-np.mean(df.iloc[:, -3]))**2)\n",
    "    variance_ver = np.sum((df.iloc[:, -2]-np.mean(df.iloc[:, -2]))**2)\n",
    "    return variance_hor/df.shape[0], variance_ver/df.shape[1]\n",
    "\n",
    "def standard_deviation_value(df):\n",
    "    variance_hor,  variance_ver = variance_value(df)\n",
    "    return np.sqrt(variance_hor), np.sqrt(variance_ver)\n",
    "\n",
    "def max_to_min_diff(df):\n",
    "    max_hor = max(df.iloc[:, -3])\n",
    "    max_ver = max(df.iloc[:, -2])\n",
    "    min_hor = min(df.iloc[:, -3])\n",
    "    min_ver = min(df.iloc[:, -2])\n",
    "    return max_hor-min_hor, max_ver-min_ver\n",
    "\n",
    "def skewness_value(df):\n",
    "    std_dev_hor, std_dev_ver = standard_deviation_value(df)\n",
    "    skewness_hor = np.sum((df.iloc[:, -3]-np.mean(df.iloc[:, -3]))**3)/((df.shape[0]-1)*(std_dev_hor**3))\n",
    "    skewness_ver = np.sum((df.iloc[:, -2]-np.mean(df.iloc[:, -2]))**3)/((df.shape[0]-1)*(std_dev_ver**3))\n",
    "    return skewness_hor, skewness_ver\n",
    "\n",
    "def kurtosis_value(df):\n",
    "    std_dev_hor, std_dev_ver = standard_deviation_value(df)\n",
    "    kurtosis_hor = np.sum((df.iloc[:, -3]-np.mean(df.iloc[:, -3]))**4)/((df.shape[0]-1)*(std_dev_hor**4))\n",
    "    kurtosis_ver = np.sum((df.iloc[:, -2]-np.mean(df.iloc[:, -2]))**4)/((df.shape[0]-1)*(std_dev_ver**4))\n",
    "    return kurtosis_hor, kurtosis_ver\n",
    "\n",
    "\n",
    "def skewness_factor_value(df):\n",
    "    skewness_hor, skewness_ver = skewness_value(df)\n",
    "    rms_hor, rms_ver = rms_value(df)\n",
    "    skewness_factor_hor = skewness_hor/(rms_hor**3)\n",
    "    skewness_factor_ver = skewness_ver/(rms_ver**3)\n",
    "    return skewness_factor_hor, skewness_factor_ver\n",
    "\n",
    "def kurtosis_factor_value(df):\n",
    "    kurtosis_hor, kurtosis_ver = kurtosis_value(df)\n",
    "    rms_hor, rms_ver = rms_value(df)\n",
    "    kurtosis_factor_hor = kurtosis_hor/(rms_hor**4)\n",
    "    kurtosis_factor_ver = kurtosis_ver/(rms_ver**4)\n",
    "    return kurtosis_factor_hor, kurtosis_factor_ver\n",
    "\n",
    "def crest_factor_value(df):\n",
    "    peak_hor, peak_ver = peak_value(df)\n",
    "    rms_hor, rms_ver = rms_value(df)\n",
    "    crest_factor_hor = peak_hor/rms_hor\n",
    "    crest_factor_ver = peak_ver/rms_ver\n",
    "    return crest_factor_hor, crest_factor_ver\n",
    "\n",
    "def shape_factor_value(df):\n",
    "    rms_hor, rms_ver = rms_value(df)\n",
    "    mean_abs_hor, mean_abs_ver = mean_absolute_value(df)\n",
    "    shape_factor_hor = rms_hor/mean_abs_hor \n",
    "    shape_factor_ver = rms_ver/mean_abs_ver\n",
    "    return shape_factor_hor, shape_factor_ver\n",
    "\n",
    "def impulse_factor_value(df):\n",
    "    peak_hor, peak_ver = peak_value(df)\n",
    "    mean_abs_hor, mean_abs_ver = mean_absolute_value(df)\n",
    "    impulse_factor_hor = peak_hor/mean_abs_hor\n",
    "    impulse_factor_ver = peak_ver/mean_abs_ver\n",
    "    return impulse_factor_hor, impulse_factor_ver\n",
    "\n",
    "def clearance_factor_value(df):\n",
    "    peak_hor, peak_ver = peak_value(df)\n",
    "    root_amplitude_hor, root_amplitude_ver = root_amplitude_value(df)\n",
    "    clearance_factor_hor = peak_hor/root_amplitude_hor\n",
    "    clearance_factor_ver = peak_ver/root_amplitude_ver\n",
    "    return clearance_factor_hor, clearance_factor_ver\n",
    "\n",
    "def coef_of_variance_value(df):\n",
    "    variance_hor, variance_ver = variance_value(df)\n",
    "    mean_abs_hor, mean_abs_ver = mean_absolute_value(df)\n",
    "    coef_of_variance_hor = np.sqrt(variance_hor)/mean_abs_hor\n",
    "    coef_of_variance_ver = np.sqrt(variance_ver)/mean_abs_ver\n",
    "    return coef_of_variance_hor, coef_of_variance_ver\n",
    "\n",
    "\n",
    "def feature_extraction(df):\n",
    "    features_df = []\n",
    "    mean_abs_hor, mean_abs_ver = mean_absolute_value(df)\n",
    "    peak_hor, peak_ver = peak_value(df)\n",
    "    min_hor, min_ver = min_value(df)\n",
    "    mean_hor, mean_ver = mean_value(df)\n",
    "    max_hor, max_ver = max_value(df)\n",
    "    rms_hor, rms_ver = rms_value(df)\n",
    "    root_amplitude_hor, root_amplitude_ver = root_amplitude_value(df)\n",
    "    variance_hor, variance_ver = variance_value(df)\n",
    "    std_dev_hor, std_dev_ver = standard_deviation_value(df)\n",
    "    max_min_diff_hor, max_min_diff_ver = max_to_min_diff(df)\n",
    "    skewness_hor, skewness_ver = skewness_value(df)\n",
    "    kurtosis_hor, kurtosis_ver = kurtosis_value(df)\n",
    "    skewness_factor_hor, skewness_factor_ver = skewness_factor_value(df)\n",
    "    kurtosis_factor_hor, kurtosis_factor_ver = kurtosis_factor_value(df)\n",
    "    crest_factor_hor, crest_factor_ver = crest_factor_value(df)\n",
    "    shape_factor_hor, shape_factor_ver = shape_factor_value(df)\n",
    "    impulse_factor_hor, impulse_factor_ver = impulse_factor_value(df)\n",
    "    clearance_factor_hor, clearance_factor_ver = clearance_factor_value(df)\n",
    "    coef_of_variance_hor, coef_of_variance_ver = coef_of_variance_value(df)\n",
    "        \n",
    "    features_df.append([rms_hor, rms_ver, mean_hor, mean_ver, mean_abs_hor, mean_abs_ver, peak_hor, peak_ver, min_hor, min_ver, max_hor, max_ver, root_amplitude_hor, root_amplitude_ver, \n",
    "                variance_hor, variance_ver, \n",
    "                std_dev_hor, std_dev_ver, \n",
    "                max_min_diff_hor, max_min_diff_ver,\n",
    "                skewness_hor, skewness_ver,\n",
    "                kurtosis_hor, kurtosis_ver,\n",
    "                skewness_factor_hor, skewness_factor_ver,\n",
    "                kurtosis_factor_hor, kurtosis_factor_ver,\n",
    "                crest_factor_hor, crest_factor_ver,\n",
    "                shape_factor_hor, shape_factor_ver,\n",
    "                impulse_factor_hor, impulse_factor_ver,\n",
    "                clearance_factor_hor, clearance_factor_ver,\n",
    "                coef_of_variance_hor, coef_of_variance_ver])\n",
    "    \n",
    "    columns = [\"rms_hor\", \"rms_ver\", \"mean_hor\", \"mean_ver\", \"mean_abs_hor\", \"mean_abs_ver\", \"peak_hor\", \"peak_ver\", \"min_hor\", \"min_ver\", \n",
    "           \"max_hor\", \"max_ver\", \"root_amplitude_hor\", \"root_amplitude_ver\", \"variance_hor\", \"variance_ver\", \"std_dev_hor\", \"std_dev_ver\", \n",
    "           \"max_min_diff_hor\", \"max_min_diff_ver\",\"skewness_hor\", \"skewness_ver\", \"kurtosis_hor\", \"kurtosis_ver\", \"skewness_factor_hor\", \"skewness_factor_ver\",\n",
    "            \"kurtosis_factor_hor\", \"kurtosis_factor_ver\", \"crest_factor_hor\", \"crest_factor_ver\", \"shape_factor_hor\", \"shape_factor_ver\", \n",
    "            \"impulse_factor_hor\", \"impulse_factor_ver\", \"clearance_factor_hor\", \"clearance_factor_ver\", \"coef_of_variance_hor\", \"coef_of_variance_ver\"]\n",
    "\n",
    "    features_df = pd.DataFrame(features_df, columns=columns)\n",
    "    return features_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e507eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bearing1_1\n",
      "Timestamp where the Ball bearing failed:  62429.12836\n",
      "min:  34726.86566\n",
      "✅ Completed feature extraction for Bearing1_1\n",
      "Processing Bearing2_1\n",
      "Timestamp where the Ball bearing failed:  38165.91328\n",
      "min:  29655.88441\n",
      "✅ Completed feature extraction for Bearing2_1\n",
      "Processing Bearing3_1\n",
      "Timestamp where the Ball bearing failed:  38169.21875\n",
      "min:  33039.11879\n",
      "✅ Completed feature extraction for Bearing3_1\n",
      "Processing Bearing1_2\n",
      "Timestamp where the Ball bearing failed:  32895.27527\n",
      "min:  31625.19691\n",
      "✅ Completed feature extraction for Bearing1_2\n",
      "Processing Bearing2_2\n",
      "Timestamp where the Ball bearing failed:  35563.57141\n",
      "min:  27633.54066\n",
      "✅ Completed feature extraction for Bearing2_2\n",
      "Processing Bearing3_2\n",
      "Timestamp where the Ball bearing failed:  47212.021953\n",
      "min:  30881.97816\n",
      "✅ Completed feature extraction for Bearing3_2\n",
      "Check data/train for feature files\n"
     ]
    }
   ],
   "source": [
    "# iterate all the files and find the occurence of first acceleration exceeding 20g\n",
    "# collect that index and its time stamp\n",
    "\n",
    "#processing training data\n",
    "paths = ['../data/train/Bearing1_1/', '../data/train/Bearing2_1/', '../data/train/Bearing3_1/', '../data/train/Bearing1_2/', '../data/train/Bearing2_2/', '../data/train/Bearing3_2/']\n",
    "\n",
    "for path in paths:\n",
    "    print(f\"Processing {path[14:-1]}\")\n",
    "    features_df = []\n",
    "    num_csv = sum(\n",
    "        1 for f in Path(path).glob(\"acc*.csv\")\n",
    "    )\n",
    "    \n",
    "    failing_time_stamp = 0\n",
    "    flag = 0\n",
    "\n",
    "\n",
    "    # for each acc file, extract all the features and append time stamp\n",
    "    for i in range(1, num_csv):\n",
    "        n = int(math.log10(i))+1\n",
    "        filepath = path + f\"acc_{(5-n)*'0'}{i}.csv\"\n",
    "        df = pd.read_csv(filepath, header=None)\n",
    "\n",
    "        # it might appear that in some training files, failing threshold (20g) is not hit, \n",
    "        # so considering failing_time_stamp as the last timestamp of every file in case we don't hit failing threshold\n",
    "        failing_time_stamp = df.iloc[-1, 0]*60*60+df.iloc[-1, 1]*60+df.iloc[-1, 2]+ df.iloc[-1, 3]*(1e-6)\n",
    "\n",
    "        # find the failing time_stamp\n",
    "        if ((max(df.iloc[:, -2])>20 or max(df.iloc[:, -1])>20) and flag==0):\n",
    "            x = np.argmax((df.iloc[:, -2] > 20) | (df.iloc[:, -1] > 20))\n",
    "            failing_time_stamp = df.iloc[x, 0]*60*60+df.iloc[x, 1]*60+df.iloc[x, 2]+ df.iloc[x, 3]*(1e-6)\n",
    "            flag = 1\n",
    "\n",
    "        if flag == 0:\n",
    "            features_df_single = feature_extraction(df)\n",
    "            features_df_single[\"time_stamp\"] = df.iloc[0, 0]*60*60+df.iloc[0, 1]*60+df.iloc[0, 2]+ df.iloc[0, 3]*(1e-6)\n",
    "            features_df.append(features_df_single)\n",
    "        else:\n",
    "            features_df_single = feature_extraction(df.iloc[:x+1])\n",
    "            features_df_single[\"time_stamp\"] = df.iloc[0, 0]*60*60+df.iloc[0, 1]*60+df.iloc[0, 2]+ df.iloc[0, 3]*(1e-6)\n",
    "            features_df.append(features_df_single)\n",
    "            break\n",
    "\n",
    "\n",
    "    print(\"Timestamp where the Ball bearing failed: \", failing_time_stamp)\n",
    "\n",
    "    features_df = pd.concat(features_df, ignore_index=True)\n",
    "\n",
    "    # calculate RUL by subtracting current time from failing_time_stamp\n",
    "    features_df[\"rul_value\"] = failing_time_stamp - features_df.loc[:, \"time_stamp\"]\n",
    "    features_df[\"time_stamp\"] -= features_df[\"time_stamp\"].min()\n",
    "\n",
    "    # convert features dataframe to a csv file for convenience\n",
    "    features_df.to_csv(f\"../data/train/{path[14:-1]}_features.csv\")\n",
    "\n",
    "    print(f\"✅ Completed feature extraction for {path[14:-1]}\")\n",
    "\n",
    "print(\"Check data/train for feature files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e788543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with index 2120 and 2121 as these rows carried faulty data.\n",
    "df = pd.read_csv('../data/train/Bearing1_1_features.csv')\n",
    "df = df.drop([2120, 2121])\n",
    "df[\"time_stamp\"] -= df[\"time_stamp\"].min()\n",
    "df.to_csv(f\"../data/train/Bearing1_1_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
