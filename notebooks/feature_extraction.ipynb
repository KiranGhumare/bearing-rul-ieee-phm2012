{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95b416bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating Remaining Useful Life of Ball Bearings\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimating Remaining Useful Life of Ball Bearings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c5bfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d6e7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_value(df):\n",
    "    mean_abs_hor= np.sum(abs(df.iloc[:, -3]))\n",
    "    mean_abs_ver= np.sum(abs(df.iloc[:, -2]))\n",
    "    mean_abs_hor = mean_abs_hor/df.shape[0]\n",
    "    mean_abs_ver = mean_abs_ver/df.shape[0]\n",
    "    return mean_abs_hor, mean_abs_ver\n",
    "\n",
    "def peak_value(df):\n",
    "    peak_hor = max(abs(df.iloc[:, -3]))\n",
    "    peak_ver = max(abs(df.iloc[:, -2]))\n",
    "    return peak_hor, peak_ver\n",
    "\n",
    "def min_value(df):\n",
    "    min_hor = min(abs(df.iloc[:, -3]))\n",
    "    min_ver = min(abs(df.iloc[:, -2]))\n",
    "    return min_hor, min_ver\n",
    "\n",
    "def mean_value(df):\n",
    "    mean_hor = np.sum(df.iloc[:, -3])\n",
    "    mean_ver = np.sum(df.iloc[:, -2])\n",
    "    mean_hor = mean_hor/df.shape[0]\n",
    "    mean_ver = mean_ver/df.shape[0]\n",
    "    return mean_hor, mean_ver\n",
    "\n",
    "def max_value(df):\n",
    "    max_hor = max(abs(df.iloc[:, -3]))\n",
    "    max_ver = max(abs(df.iloc[:, -2]))\n",
    "    return max_hor, max_ver\n",
    "\n",
    "def rms_value(df):\n",
    "    rms_hor= np.sum(df.iloc[:, -3]**2)\n",
    "    rms_ver= np.sum(df.iloc[:, -2]**2)\n",
    "    rms_hor = np.sqrt(rms_hor/df.shape[0])\n",
    "    rms_ver = np.sqrt(rms_ver/df.shape[0])\n",
    "    return rms_hor, rms_ver\n",
    "\n",
    "def root_amplitude_value(df):\n",
    "    root_amplitude_hor = np.sum(np.sqrt(abs(df.iloc[:, -3]**2)))\n",
    "    root_amplitude_ver = np.sum(np.sqrt(abs(df.iloc[:, -2]**2)))\n",
    "    root_amplitude_hor = (root_amplitude_hor/df.shape[0])**2\n",
    "    root_amplitude_ver = (root_amplitude_ver/df.shape[0])**2\n",
    "    return root_amplitude_hor, root_amplitude_ver\n",
    "\n",
    "def variance_value(df):\n",
    "    variance_hor = np.sum((df.iloc[:, -3]-np.mean(df.iloc[:, -3]))**2)\n",
    "    variance_ver = np.sum((df.iloc[:, -2]-np.mean(df.iloc[:, -2]))**2)\n",
    "    return variance_hor/df.shape[0], variance_ver/df.shape[1]\n",
    "\n",
    "def standard_deviation_value(df):\n",
    "    variance_hor,  variance_ver = variance_value(df)\n",
    "    return np.sqrt(variance_hor), np.sqrt(variance_ver)\n",
    "\n",
    "def max_to_min_diff(df):\n",
    "    max_hor = max(df.iloc[:, -3])\n",
    "    max_ver = max(df.iloc[:, -2])\n",
    "    min_hor = min(df.iloc[:, -3])\n",
    "    min_ver = min(df.iloc[:, -2])\n",
    "    return max_hor-min_hor, max_ver-min_ver\n",
    "\n",
    "def skewness_value(df):\n",
    "    std_dev_hor, std_dev_ver = standard_deviation_value(df)\n",
    "    skewness_hor = np.sum((df.iloc[:, -3]-np.mean(df.iloc[:, -3]))**3)/((df.shape[0]-1)*(std_dev_hor**3))\n",
    "    skewness_ver = np.sum((df.iloc[:, -2]-np.mean(df.iloc[:, -2]))**3)/((df.shape[0]-1)*(std_dev_ver**3))\n",
    "    return skewness_hor, skewness_ver\n",
    "\n",
    "def kurtosis_value(df):\n",
    "    std_dev_hor, std_dev_ver = standard_deviation_value(df)\n",
    "    kurtosis_hor = np.sum((df.iloc[:, -3]-np.mean(df.iloc[:, -3]))**4)/((df.shape[0]-1)*(std_dev_hor**4))\n",
    "    kurtosis_ver = np.sum((df.iloc[:, -2]-np.mean(df.iloc[:, -2]))**4)/((df.shape[0]-1)*(std_dev_ver**4))\n",
    "    return kurtosis_hor, kurtosis_ver\n",
    "\n",
    "\n",
    "def skewness_factor_value(df):\n",
    "    skewness_hor, skewness_ver = skewness_value(df)\n",
    "    rms_hor, rms_ver = rms_value(df)\n",
    "    skewness_factor_hor = skewness_hor/(rms_hor**3)\n",
    "    skewness_factor_ver = skewness_ver/(rms_ver**3)\n",
    "    return skewness_factor_hor, skewness_factor_ver\n",
    "\n",
    "def kurtosis_factor_value(df):\n",
    "    kurtosis_hor, kurtosis_ver = kurtosis_value(df)\n",
    "    rms_hor, rms_ver = rms_value(df)\n",
    "    kurtosis_factor_hor = kurtosis_hor/(rms_hor**4)\n",
    "    kurtosis_factor_ver = kurtosis_ver/(rms_ver**4)\n",
    "    return kurtosis_factor_hor, kurtosis_factor_ver\n",
    "\n",
    "def crest_factor_value(df):\n",
    "    peak_hor, peak_ver = peak_value(df)\n",
    "    rms_hor, rms_ver = rms_value(df)\n",
    "    crest_factor_hor = peak_hor/rms_hor\n",
    "    crest_factor_ver = peak_ver/rms_ver\n",
    "    return crest_factor_hor, crest_factor_ver\n",
    "\n",
    "def shape_factor_value(df):\n",
    "    rms_hor, rms_ver = rms_value(df)\n",
    "    mean_abs_hor, mean_abs_ver = mean_absolute_value(df)\n",
    "    shape_factor_hor = rms_hor/mean_abs_hor \n",
    "    shape_factor_ver = rms_ver/mean_abs_ver\n",
    "    return shape_factor_hor, shape_factor_ver\n",
    "\n",
    "def impulse_factor_value(df):\n",
    "    peak_hor, peak_ver = peak_value(df)\n",
    "    mean_abs_hor, mean_abs_ver = mean_absolute_value(df)\n",
    "    impulse_factor_hor = peak_hor/mean_abs_hor\n",
    "    impulse_factor_ver = peak_ver/mean_abs_ver\n",
    "    return impulse_factor_hor, impulse_factor_ver\n",
    "\n",
    "def clearance_factor_value(df):\n",
    "    peak_hor, peak_ver = peak_value(df)\n",
    "    root_amplitude_hor, root_amplitude_ver = root_amplitude_value(df)\n",
    "    clearance_factor_hor = peak_hor/root_amplitude_hor\n",
    "    clearance_factor_ver = peak_ver/root_amplitude_ver\n",
    "    return clearance_factor_hor, clearance_factor_ver\n",
    "\n",
    "def coef_of_variance_value(df):\n",
    "    variance_hor, variance_ver = variance_value(df)\n",
    "    mean_abs_hor, mean_abs_ver = mean_absolute_value(df)\n",
    "    coef_of_variance_hor = np.sqrt(variance_hor)/mean_abs_hor\n",
    "    coef_of_variance_ver = np.sqrt(variance_ver)/mean_abs_ver\n",
    "    return coef_of_variance_hor, coef_of_variance_ver\n",
    "\n",
    "def mean_rul_value(df):\n",
    "    return np.mean(df.iloc[:, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e507eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate all the files and find the occurence of first acceleration exceeding 20g\n",
    "# collect that index and its time stamp\n",
    "path = '../data/train/Bearing1_1/'\n",
    "\n",
    "num_csv = sum(\n",
    "    1 for f in Path(path).glob(\"acc*.csv\")\n",
    ")\n",
    "\n",
    "dfs = []\n",
    "index = 0\n",
    "failing_time_stamp = 0\n",
    "\n",
    "for i in range(1, num_csv):\n",
    "    n = int(math.log10(i))+1\n",
    "    filepath = path + f\"acc_{(5-n)*'0'}{i}.csv\"\n",
    "    df = pd.read_csv(filepath, header=None)\n",
    "    if (max(df.iloc[:, -2])>20):\n",
    "        x = np.argmin(df.iloc[:, -2]>20)\n",
    "        index+=x\n",
    "        failing_time_stamp = df.iloc[x, 0]*60+df.iloc[x, 1]+df.iloc[x, 2]/60+ df.iloc[x, 3]*(1e-6)/60\n",
    "        dfs.append(df.iloc[0:x, :])\n",
    "        break\n",
    "    elif (max(df.iloc[:, -1])>20):\n",
    "        x = np.argmin(df.iloc[:, -1]>20)\n",
    "        index+=x\n",
    "        failing_time_stamp = df.iloc[x, 0]*60+df.iloc[x, 1]+df.iloc[x, 2]/60+ df.iloc[x, 3]*(1e-6)/60\n",
    "        dfs.append(df.iloc[0:x, :])\n",
    "        break\n",
    "    index+=df.shape[0]\n",
    "    dfs.append(df)\n",
    "    \n",
    "rul_values = pd.concat(dfs, ignore_index=True)\n",
    "rul_values.columns = [\n",
    "    'hour',\n",
    "    'min',\n",
    "    'seconds',\n",
    "    'microseconds',\n",
    "    'hor_acc',\n",
    "    'ver_acc'\n",
    "]\n",
    "\n",
    "# reiterate the files again and calculate the RUL for each data point\n",
    "timestamps = rul_values.iloc[:, 0]*60+rul_values.iloc[:, 1]+rul_values.iloc[:, 2]/60+rul_values.iloc[:, 3]*(1e-6)/60\n",
    "rul_values = rul_values.assign(rul_values=failing_time_stamp - timestamps)\n",
    "rul_values.to_csv(\"../data/train/rul_values.csv\", index=False)\n",
    "# reiterate the files and set RUL to 0 for all the indices above the collected index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d5b1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all acc and temp files as per bearings\n",
    "features_df = []\n",
    "second_counter = 1\n",
    "\n",
    "df = pd.read_csv('../data/train/rul_values.csv')\n",
    "length = df.shape[0]\n",
    "\n",
    "second = df.iloc[0, 2]\n",
    "start = 0\n",
    "\n",
    "for i in range(length):\n",
    "    if (df.iloc[i, 2]!=second):\n",
    "        mean_abs_hor, mean_abs_ver = mean_absolute_value(df.iloc[start:i])\n",
    "        peak_hor, peak_ver = peak_value(df.iloc[start:i])\n",
    "        min_hor, min_ver = min_value(df.iloc[start:i])\n",
    "        mean_hor, mean_ver = mean_value(df.iloc[start:i])\n",
    "        max_hor, max_ver = max_value(df.iloc[start:i])\n",
    "        rms_hor, rms_ver = rms_value(df.iloc[start:i])\n",
    "        root_amplitude_hor, root_amplitude_ver = root_amplitude_value(df.iloc[start:i])\n",
    "        variance_hor, variance_ver = variance_value(df.iloc[start:i])\n",
    "        std_dev_hor, std_dev_ver = standard_deviation_value(df.iloc[start:i])\n",
    "        max_min_diff_hor, max_min_diff_ver = max_to_min_diff(df.iloc[start:i])\n",
    "        skewness_hor, skewness_ver = skewness_value(df.iloc[start:i])\n",
    "        kurtosis_hor, kurtosis_ver = kurtosis_value(df.iloc[start:i])\n",
    "        skewness_factor_hor, skewness_factor_ver = skewness_factor_value(df.iloc[start:i])\n",
    "        kurtosis_factor_hor, kurtosis_factor_ver = kurtosis_factor_value(df.iloc[start:i])\n",
    "        crest_factor_hor, crest_factor_ver = crest_factor_value(df.iloc[start:i])\n",
    "        shape_factor_hor, shape_factor_ver = shape_factor_value(df.iloc[start:i])\n",
    "        impulse_factor_hor, impulse_factor_ver = impulse_factor_value(df.iloc[start:i])\n",
    "        clearance_factor_hor, clearance_factor_ver = clearance_factor_value(df.iloc[start:i])\n",
    "        coef_of_variance_hor, coef_of_variance_ver = coef_of_variance_value(df.iloc[start:i])\n",
    "        mean_rul = mean_rul_value(df.iloc[start:i])\n",
    "        \n",
    "        features_df.append([second_counter, rms_hor, rms_ver, mean_hor, mean_ver, mean_abs_hor, mean_abs_ver, peak_hor, peak_ver, min_hor, min_ver, max_hor, max_ver, root_amplitude_hor, root_amplitude_ver, \n",
    "                   variance_hor, variance_ver, \n",
    "                   std_dev_hor, std_dev_ver, \n",
    "                   max_min_diff_hor, max_min_diff_ver,\n",
    "                   skewness_hor, skewness_ver,\n",
    "                   kurtosis_hor, kurtosis_ver,\n",
    "                   skewness_factor_hor, skewness_factor_ver,\n",
    "                   kurtosis_factor_hor, kurtosis_factor_ver,\n",
    "                   crest_factor_hor, crest_factor_ver,\n",
    "                   shape_factor_hor, shape_factor_ver,\n",
    "                   impulse_factor_hor, impulse_factor_ver,\n",
    "                   clearance_factor_hor, clearance_factor_ver,\n",
    "                   coef_of_variance_hor, coef_of_variance_ver, mean_rul])\n",
    "        second = df.iloc[i, 2]\n",
    "        start = i\n",
    "        second_counter+=1\n",
    "\n",
    "columns = [\"second_counter\", \"rms_hor\", \"rms_ver\", \"mean_hor\", \"mean_ver\", \"mean_abs_hor\", \"mean_abs_ver\", \"peak_hor\", \"peak_ver\", \"min_hor\", \"min_ver\", \n",
    "           \"max_hor\", \"max_ver\", \"root_amplitude_hor\", \"root_amplitude_ver\", \"variance_hor\", \"variance_ver\", \"std_dev_hor\", \"std_dev_ver\", \n",
    "           \"max_min_diff_hor\", \"max_min_diff_ver\",\"skewness_hor\", \"skewness_ver\", \"kurtosis_hor\", \"kurtosis_ver\", \"skewness_factor_hor\", \"skewness_factor_ver\",\n",
    "            \"kurtosis_factor_hor\", \"kurtosis_factor_ver\", \"crest_factor_hor\", \"crest_factor_ver\", \"shape_factor_hor\", \"shape_factor_ver\", \n",
    "            \"impulse_factor_hor\", \"impulse_factor_ver\", \"clearance_factor_hor\", \"clearance_factor_ver\", \"coef_of_variance_hor\", \"coef_of_variance_ver\", \"mean_rul\"]\n",
    "\n",
    "features_df = pd.DataFrame(features_df, columns=columns)\n",
    "features_df.to_csv(\"../data/train/features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
